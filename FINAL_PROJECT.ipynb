{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alphaizz/Insurance/blob/main/FINAL_PROJECT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 1: Data Loading & All Variable Calculation"
      ],
      "metadata": {
        "id": "FDpKRwaHdIcL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iww4ndY2LRyK",
        "outputId": "b7f07488-0924-4beb-cdd0-17d06a277c3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Baris Data Ditemukan: 22159\n",
            "Data Kualitas (termasuk nilai nol) telah disimpan sebagai 'eda_data_quality_zero_bar_chart.png'\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import math # Diperlukan untuk konversi float\n",
        "\n",
        "file_name = 'data-1-Daily-Activity.csv'\n",
        "invalid_counts = {} # Sekarang mencakup nilai 0 dan ''\n",
        "total_records = 0\n",
        "relevant_cols = {\n",
        "    0: 'distance_meters',\n",
        "    1: 'moving_time_seconds',\n",
        "    6: 'average_speed_kmh',\n",
        "    8: 'average_heartrate_bpm',\n",
        "    9: 'average_cadence_spm'\n",
        "}\n",
        "\n",
        "# Inisialisasi hitungan\n",
        "for col_index in relevant_cols.keys():\n",
        "    invalid_counts[col_index] = 0\n",
        "\n",
        "# --- 1. PENGHITUNGAN MANUAL NILAI NOL ATAU HILANG ---\n",
        "with open(file_name, 'r') as f:\n",
        "    reader = csv.reader(f)\n",
        "    next(reader) # Skip header\n",
        "\n",
        "    for row in reader:\n",
        "        total_records += 1\n",
        "        for index in relevant_cols.keys():\n",
        "            cell_value = row[index]\n",
        "\n",
        "            # Cek jika nilai hilang ('') ATAU nilai adalah 0 setelah konversi\n",
        "            is_invalid = False\n",
        "\n",
        "            if cell_value == '':\n",
        "                is_invalid = True\n",
        "            else:\n",
        "                try:\n",
        "                    # Konversi ke float untuk cek nilai 0\n",
        "                    if float(cell_value) == 0.0:\n",
        "                        is_invalid = True\n",
        "                except ValueError:\n",
        "                    # Jika ada error konversi (data rusak), anggap tidak valid juga\n",
        "                    is_invalid = True\n",
        "\n",
        "            if is_invalid:\n",
        "                invalid_counts[index] += 1\n",
        "\n",
        "# Siapkan data untuk plotting\n",
        "column_names = list(relevant_cols.values())\n",
        "invalid_data = list(invalid_counts.values())\n",
        "clean_data = [total_records - invalid for invalid in invalid_data]\n",
        "\n",
        "# --- 2. VISUALISASI STACKED BAR CHART ---\n",
        "\n",
        "x_pos = np.arange(len(column_names))\n",
        "bar_width = 0.8\n",
        "\n",
        "plt.figure(figsize=(12, 7))\n",
        "\n",
        "# Plot Data Bersih (Bagian bawah stack)\n",
        "plt.bar(x_pos, clean_data, color='#4CAF50', edgecolor='white', width=bar_width, label='Data Bersih (Nilai > 0)')\n",
        "\n",
        "# Plot Data Hilang/Nol (Bagian atas stack)\n",
        "plt.bar(x_pos, invalid_data, color='#FF5722', edgecolor='white', width=bar_width, bottom=clean_data, label='Data Hilang/Nol (Invalid)')\n",
        "\n",
        "# Tambahkan label (Total dan Jumlah Hilang/Nol)\n",
        "for i in range(len(column_names)):\n",
        "    # Total\n",
        "    plt.text(x_pos[i], total_records + 20, str(total_records), ha='center', va='bottom', fontsize=9)\n",
        "    # Invalid/Zero Count\n",
        "    if invalid_data[i] > 0:\n",
        "        # Posisikan label di tengah bagian invalid\n",
        "        text_y = clean_data[i] + invalid_data[i] / 2\n",
        "        # Cek apakah ada ruang untuk menempatkan teks (jika data bersihnya juga nol)\n",
        "        if text_y > 0 and invalid_data[i] > total_records * 0.01: # Hanya tampilkan jika angkanya cukup besar\n",
        "             plt.text(x_pos[i], text_y, str(invalid_data[i]), ha='center', va='center', color='white', fontsize=9)\n",
        "        elif invalid_data[i] > 0 and invalid_data[i] < total_records * 0.01:\n",
        "             # Teks kecil di atas bar jika angkanya terlalu kecil\n",
        "             plt.text(x_pos[i], total_records + 20, f\"({invalid_data[i]})\", ha='center', va='top', color='#FF5722', fontsize=9)\n",
        "\n",
        "plt.xlabel(\"Variabel Data Mentah\", fontsize=12)\n",
        "plt.ylabel(f\"Jumlah Baris (Total: {total_records})\", fontsize=12)\n",
        "plt.title(\"Kualitas Data Mentah: Data Bersih vs. Data Hilang/Nol (0)\", fontsize=14)\n",
        "plt.xticks(x_pos, column_names, rotation=25, ha='right')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig('eda_data_quality_zero_bar_chart.png')\n",
        "plt.close()\n",
        "\n",
        "print(f\"Total Baris Data Ditemukan: {total_records}\")\n",
        "print(\"Data Kualitas (termasuk nilai nol) telah disimpan sebagai 'eda_data_quality_zero_bar_chart.png'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 2: Visualization - The \"Why 3 Variables?\" Heatmap"
      ],
      "metadata": {
        "id": "WP7pyF9NdKqa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sambungan dari PART 1 (menggunakan aggregated_data_dicts dan fungsi helper)\n",
        "\n",
        "# --- A. PERSIAPAN DATA UNTUK KORELASI (6 FITUR) ---\n",
        "\n",
        "# Kolom yang akan digunakan untuk Heatmap\n",
        "cols = list(aggregated_data_dicts[0].keys()) # Mengambil 6 kunci/nama fitur\n",
        "num_cols = len(cols)\n",
        "corr_matrix = [[0] * num_cols for _ in range(num_cols)]\n",
        "\n",
        "# Transpose data: mengubah list of dicts menjadi list of columns/lists\n",
        "# Ini dibutuhkan oleh fungsi calculate_correlation\n",
        "col_lists = {col: [d[col] for d in aggregated_data_dicts] for col in cols}\n",
        "\n",
        "# --- B. PERHITUNGAN MANUAL MATRIKS KORELASI ---\n",
        "for i in range(num_cols):\n",
        "    for j in range(i, num_cols):\n",
        "        # Gunakan fungsi helper calculate_correlation()\n",
        "        corr = calculate_correlation(col_lists[cols[i]], col_lists[cols[j]])\n",
        "        corr_matrix[i][j] = corr\n",
        "        corr_matrix[j][i] = corr # Matriks korelasi bersifat simetris\n",
        "\n",
        "print(\"Matriks Korelasi (6x6) berhasil dihitung secara manual.\")\n",
        "\n",
        "\n",
        "# --- C. VISUALISASI CORRELATION HEATMAP (Visualisasi Diizinkan) ---\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(\n",
        "    corr_matrix,\n",
        "    annot=True,        # Menampilkan nilai korelasi\n",
        "    fmt=\".2f\",         # Format 2 angka desimal\n",
        "    cmap='coolwarm',   # Skema warna\n",
        "    linewidths=.5,     # Garis pemisah\n",
        "    xticklabels=cols,\n",
        "    yticklabels=cols,\n",
        "    cbar_kws={'label': 'Koefisien Korelasi'}\n",
        ")\n",
        "plt.title('Correlation Heatmap (Justifikasi Variabel)', fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.savefig('manual_correlation_heatmap.png')\n",
        "plt.close()\n",
        "\n",
        "# Tampilkan Heatmap sebagai bukti\n",
        "#\n",
        "print(\"Heatmap korelasi telah disimpan sebagai 'manual_correlation_heatmap.png'.\")\n",
        "\n",
        "\n",
        "# --- D. KESIMPULAN & SELEKSI 3 FITUR AKHIR ---\n",
        "\n",
        "# Berdasarkan Heatmap, kami mengonfirmasi bahwa Total_Distance, Moving_Time,\n",
        "# dan Frequency sangat berkorelasi (redundant).\n",
        "\n",
        "# 3 Fitur Final yang dipilih:\n",
        "# 1. Volume: Total_Distance (Mewakili Volume Aktivitas)\n",
        "# 2. Intensitas: Avg_Speed (Mewakili Intensitas Aktivitas)\n",
        "# 3. Fisiologi: Avg_Heart_Rate (Mewakili Respon Tubuh)\n",
        "\n",
        "clustering_features = [] # Data yang akan digunakan untuk K-Means (sudah Log Transformed dan Scaled)\n",
        "original_features = []   # Data yang akan digunakan untuk pelaporan (nilai asli)\n",
        "filtered_badges = []     # List baru untuk menyimpan Badge_IDs pengguna yang valid\n",
        "\n",
        "features_to_select = ['Total_Distance', 'Avg_Speed', 'Avg_Heart_Rate']\n",
        "\n",
        "# Iterate through aggregated_data_dicts and corresponding badges simultaneously\n",
        "for i, data in enumerate(aggregated_data_dicts):\n",
        "\n",
        "    # 1. TERAPAN ATURAN KETAT (DATA LENGKAP SAJA)\n",
        "    # Periksa apakah SEMUA 3 fitur kunci bernilai 0\n",
        "    is_valid_user = True\n",
        "    for feature in features_to_select:\n",
        "        if data[feature] == 0:\n",
        "            is_valid_user = False\n",
        "            break\n",
        "\n",
        "    if not is_valid_user:\n",
        "        # Jika salah satu fitur kunci bernilai 0, pengguna di-skip\n",
        "        continue\n",
        "\n",
        "    # 2. LOG TRANSFORM PADA DATA YANG VALID\n",
        "    # Menggunakan Log(X + 1)\n",
        "    log_dist = math.log(data['Total_Distance'] + 1)\n",
        "    log_speed = math.log(data['Avg_Speed'] + 1)\n",
        "    avg_hr = data['Avg_Heart_Rate'] # Tidak di-Log Transform\n",
        "\n",
        "    # Simpan fitur untuk Clustering dan Pelaporan\n",
        "    clustering_features.append([log_dist, log_speed, avg_hr])\n",
        "    original_features.append({'Total_Distance': data['Total_Distance'], 'Avg_Speed': data['Avg_Speed'], 'Avg_Heart_Rate': avg_hr})\n",
        "    filtered_badges.append(badges[i]) # Simpan Badge_ID pengguna yang valid\n",
        "\n",
        "# `display_data` is used in Part 4 for CSV output. It needs to be a list of lists.\n",
        "display_data = [[item['Total_Distance'], item['Avg_Speed'], item['Avg_Heart_Rate']] for item in original_features]\n",
        "\n",
        "print(f\"\\nPART 2 SELESAI. Jumlah pengguna yang lolos 'Data Lengkap (Non-Zero)' adalah: {len(clustering_features)} dari {len(aggregated_data_dicts)}.\")"
      ],
      "metadata": {
        "id": "s2iZoQI0dDc5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76311cc9-d937-42fd-a11c-787310cdecbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matriks Korelasi (6x6) berhasil dihitung secara manual.\n",
            "Heatmap korelasi telah disimpan sebagai 'manual_correlation_heatmap.png'.\n",
            "\n",
            "PART 2 SELESAI. Jumlah pengguna yang lolos 'Data Lengkap (Non-Zero)' adalah: 240 dari 658.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "insert_id_1",
        "outputId": "a034bced-3a5f-4632-9593-a961f140fe43"
      },
      "source": [
        "import csv\n",
        "import math\n",
        "import numpy as np # Already imported, but good practice to ensure.\n",
        "import seaborn as sns # Needed for heatmap in next cell\n",
        "import random # Needed for manual_kmeans later\n",
        "\n",
        "# Helper function for Pearson correlation coefficient\n",
        "def calculate_correlation(list1, list2):\n",
        "    # Ensure lists are not empty and have same length\n",
        "    if not list1 or not list2 or len(list1) != len(list2):\n",
        "        return 0.0\n",
        "\n",
        "    n = len(list1)\n",
        "\n",
        "    # Handle cases where all values in a list are the same (zero variance)\n",
        "    if all(x == list1[0] for x in list1) or all(y == list2[0] for y in list2):\n",
        "        return 0.0 # Correlation is undefined or 0 in such cases\n",
        "\n",
        "    mean1 = sum(list1) / n\n",
        "    mean2 = sum(list2) / n\n",
        "\n",
        "    numerator = sum((x - mean1) * (y - mean2) for x, y in zip(list1, list2))\n",
        "    denominator1 = sum((x - mean1)**2 for x in list1)\n",
        "    denominator2 = sum((y - mean2)**2 for y in list2)\n",
        "\n",
        "    denom = (denominator1**0.5) * (denominator2**0.5)\n",
        "    if denom == 0: # Should be caught by the all(x == list1[0]) check above, but for safety\n",
        "        return 0.0\n",
        "    return numerator / denom\n",
        "\n",
        "\n",
        "# --- Data Aggregation for `aggregated_data_dicts` and `badges` ---\n",
        "user_activity_data = {} # Key: user_id, Value: dict of aggregated raw metrics\n",
        "\n",
        "# `file_name` is defined in the first cell, assuming it's in scope\n",
        "with open(file_name, 'r') as f:\n",
        "    reader = csv.reader(f)\n",
        "    next(reader) # Skip header\n",
        "\n",
        "    for row_idx, row in enumerate(reader):\n",
        "        try:\n",
        "            # Assuming Badge_ID is the last column (index 10) based on typical activity data structure\n",
        "            # and inspection of `row` in kernel state from previous cell.\n",
        "            user_id = row[10]\n",
        "\n",
        "            if user_id not in user_activity_data:\n",
        "                user_activity_data[user_id] = {\n",
        "                    'Total_Distance_sum': 0.0,\n",
        "                    'Moving_Time_sum': 0.0,\n",
        "                    'Avg_Speed_vals': [], # Collect values to calculate average\n",
        "                    'Avg_Heart_Rate_vals': [],\n",
        "                    'Avg_Cadence_vals': [],\n",
        "                    'Activity_Count': 0 # For 'Frequency'\n",
        "                }\n",
        "\n",
        "            # Columns used:\n",
        "            # 0: 'distance_meters'\n",
        "            # 1: 'moving_time_seconds'\n",
        "            # 6: 'average_speed_kmh'\n",
        "            # 8: 'average_heartrate_bpm'\n",
        "            # 9: 'average_cadence_spm'\n",
        "\n",
        "            # Process Total_Distance (from index 0)\n",
        "            dist_str = row[0]\n",
        "            if dist_str != '':\n",
        "                user_activity_data[user_id]['Total_Distance_sum'] += float(dist_str)\n",
        "\n",
        "            # Process Moving_Time (from index 1)\n",
        "            time_str = row[1]\n",
        "            if time_str != '':\n",
        "                user_activity_data[user_id]['Moving_Time_sum'] += float(time_str)\n",
        "\n",
        "            # Process Avg_Speed (from index 6)\n",
        "            speed_str = row[6]\n",
        "            if speed_str != '' and float(speed_str) != 0.0:\n",
        "                user_activity_data[user_id]['Avg_Speed_vals'].append(float(speed_str))\n",
        "\n",
        "            # Process Avg_Heart_Rate (from index 8)\n",
        "            hr_str = row[8]\n",
        "            if hr_str != '' and float(hr_str) != 0.0:\n",
        "                user_activity_data[user_id]['Avg_Heart_Rate_vals'].append(float(hr_str))\n",
        "\n",
        "            # Process Avg_Cadence (from index 9)\n",
        "            cadence_str = row[9]\n",
        "            if cadence_str != '' and float(cadence_str) != 0.0:\n",
        "                user_activity_data[user_id]['Avg_Cadence_vals'].append(float(cadence_str))\n",
        "\n",
        "            # Increment activity count for Frequency\n",
        "            user_activity_data[user_id]['Activity_Count'] += 1\n",
        "\n",
        "        except (ValueError, IndexError) as e:\n",
        "            # print(f\"Warning: Skipping row {row_idx+2} due to data parsing error: {e} in row: {row}\")\n",
        "            continue # Skip problematic rows\n",
        "\n",
        "aggregated_data_dicts = []\n",
        "badges = [] # List to store Badge_IDs (user_id) for later use in Part 4\n",
        "\n",
        "for user_id, data in user_activity_data.items():\n",
        "    badges.append(user_id) # Add user_id to badges list\n",
        "\n",
        "    # Calculate final averages and create the dictionary for this user\n",
        "    avg_speed = sum(data['Avg_Speed_vals']) / len(data['Avg_Speed_vals']) if data['Avg_Speed_vals'] else 0.0\n",
        "    avg_heart_rate = sum(data['Avg_Heart_Rate_vals']) / len(data['Avg_Heart_Rate_vals']) if data['Avg_Heart_Rate_vals'] else 0.0\n",
        "    avg_cadence = sum(data['Avg_Cadence_vals']) / len(data['Avg_Cadence_vals']) if data['Avg_Cadence_vals'] else 0.0\n",
        "\n",
        "    aggregated_data_dicts.append({\n",
        "        'Total_Distance': data['Total_Distance_sum'],\n",
        "        'Moving_Time': data['Moving_Time_sum'],\n",
        "        'Avg_Speed': avg_speed,\n",
        "        'Avg_Heart_Rate': avg_heart_rate,\n",
        "        'Avg_Cadence': avg_cadence,\n",
        "        'Frequency': data['Activity_Count']\n",
        "    })\n",
        "\n",
        "print(f\"Data aggregation complete for {len(aggregated_data_dicts)} users.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data aggregation complete for 658 users.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 3: The Manual Algorithm"
      ],
      "metadata": {
        "id": "kvDe-x1ldRsZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sambungan dari PART 2 (menggunakan clustering_features, original_features,\n",
        "# dan helper functions calculate_mean, calculate_std_dev, transpose_data)\n",
        "\n",
        "# --- Helper functions for manual calculations ---\n",
        "def transpose_data(data):\n",
        "    if not data: return []\n",
        "    return [[row[i] for row in data] for i in range(len(data[0]))]\n",
        "\n",
        "def calculate_mean(data_list):\n",
        "    if not data_list: return 0.0\n",
        "    return sum(data_list) / len(data_list)\n",
        "\n",
        "def calculate_std_dev(data_list, mean):\n",
        "    if not data_list or len(data_list) < 2: return 0.0 # Standard deviation requires at least 2 points\n",
        "    variance = sum([(x - mean) ** 2 for x in data_list]) / (len(data_list) - 1)\n",
        "    return math.sqrt(variance)\n",
        "\n",
        "# 1. Manual Normalization\n",
        "def normalize(data):\n",
        "    if not data: return []\n",
        "    mins = list(data[0]) if data else []\n",
        "    maxs = list(data[0]) if data else []\n",
        "    for row in data:\n",
        "        for i in range(len(row)):\n",
        "            if row[i] < mins[i]: mins[i] = row[i]\n",
        "            if row[i] > maxs[i]: maxs[i] = row[i]\n",
        "    norm = []\n",
        "    for row in data:\n",
        "        new_row = []\n",
        "        for i in range(len(row)):\n",
        "            denom = maxs[i] - mins[i]\n",
        "            val = (row[i] - mins[i]) / denom if denom > 0 else 0\n",
        "            new_row.append(val)\n",
        "        norm.append(new_row)\n",
        "    return norm\n",
        "\n",
        "\n",
        "# 2. Euclidean Distance\n",
        "def get_dist(p1, p2):\n",
        "    return sum((p1[i]-p2[i])**2 for i in range(len(p1)))**0.5\n",
        "\n",
        "# 3. Mean Calculation (already defined, but ensuring it's here for context)\n",
        "def get_mean(vectors):\n",
        "    if not vectors: return []\n",
        "    dim = len(vectors[0])\n",
        "    sums = [0.0]*dim\n",
        "    for v in vectors:\n",
        "        for i in range(dim): sums[i]+=v[i]\n",
        "    return [s/len(vectors) for s in sums]\n",
        "\n",
        "# 4. K-Means Loop (Modified to return WSS history for Loss Curve)\n",
        "def manual_kmeans(data, k=3, iters=20):\n",
        "    random.seed(42)\n",
        "    centroids = random.sample(data, k)\n",
        "    wss_history = []  # Initialize list to store WSS at each iteration\n",
        "\n",
        "    for iter_num in range(iters):\n",
        "        clusters = [[] for _ in range(k)]\n",
        "        indices = [[] for _ in range(k)]\n",
        "\n",
        "        # Assign each data point to the closest centroid\n",
        "        for idx, p in enumerate(data):\n",
        "            dists = [get_dist(p, c) for c in centroids]\n",
        "            closest = dists.index(min(dists))\n",
        "            clusters[closest].append(p)\n",
        "            indices[closest].append(idx)\n",
        "\n",
        "        # Calculate WSS for the current clustering state\n",
        "        current_wss = 0.0\n",
        "        for i_cluster in range(k):\n",
        "            for p_in_cluster in clusters[i_cluster]:\n",
        "                if i_cluster < len(centroids) and len(centroids[i_cluster]) == len(p_in_cluster):\n",
        "                    current_wss += get_dist(p_in_cluster, centroids[i_cluster]) ** 2\n",
        "                # else: Handle empty cluster or dimension mismatch if necessary\n",
        "        wss_history.append(current_wss) # Store WSS for this iteration\n",
        "\n",
        "        # Update centroids\n",
        "        new_c = []\n",
        "        for i, c_group in enumerate(clusters):\n",
        "            if c_group:\n",
        "                new_c.append(get_mean(c_group))\n",
        "            else:\n",
        "                new_c.append(centroids[i]) # Keep old centroid if cluster is empty\n",
        "\n",
        "        print(f\"\\n--- Iterasi {iter_num + 1}/{iters} ---\")\n",
        "        for i, c in enumerate(new_c):\n",
        "            # Format centroid: (Log Dist, Log Speed, Avg HR) - assuming 3 features\n",
        "            centroid_str = f\"({c[0]:.4f}, {c[1]:.4f}, {c[2]:.4f})\"\n",
        "            size = len(indices[i])\n",
        "            print(f\"Cluster {i}: Centroid = {centroid_str}, Ukuran = {size} pengguna\")\n",
        "\n",
        "        # Check for convergence\n",
        "        if all(get_dist(centroids[i], new_c[i]) < 1e-6 for i in range(k)):\n",
        "            print(\"\\nAlgoritma Konvergen, menghentikan iterasi lebih awal.\")\n",
        "            centroids = new_c # Update centroids one last time\n",
        "            break\n",
        "        centroids = new_c\n",
        "\n",
        "    return indices, centroids, wss_history # Now returns 3 values\n",
        "\n",
        "    # 5. Calculate Within-Cluster Sum of Squares (WSS) - This function calculates final WSS\n",
        "def calculate_wss(data, k, iters=20):\n",
        "    random.seed(42)\n",
        "    if not data: return 0.0\n",
        "    if len(data) < k: # Handle case where k is greater than number of data points\n",
        "        # Optionally, raise an error or return a specific value\n",
        "        print(\"Warning: k is greater than the number of data points. Adjusting k.\")\n",
        "        k = len(data)\n",
        "        if k == 0: return 0.0\n",
        "\n",
        "    centroids = random.sample(data, k)\n",
        "\n",
        "    for _ in range(iters):\n",
        "        clusters = [[] for _ in range(k)]\n",
        "\n",
        "        # Assign\n",
        "        for p in data:\n",
        "            dists = [get_dist(p, c) for c in centroids]\n",
        "            closest = dists.index(min(dists))\n",
        "            clusters[closest].append(p)\n",
        "\n",
        "        # Update\n",
        "        new_c = []\n",
        "        for i, c_group in enumerate(clusters):\n",
        "            if c_group: new_c.append(get_mean(c_group))\n",
        "            else: new_c.append(centroids[i]) # Keep old centroid if cluster is empty\n",
        "\n",
        "\n",
        "        if all(get_dist(centroids[i], new_c[i]) < 1e-6 for i in range(k)):\n",
        "            centroids = new_c\n",
        "            break\n",
        "\n",
        "        centroids = new_c\n",
        "\n",
        "    # Hitung WSS (Sum of Squared Errors)\n",
        "    wss = 0\n",
        "    for i in range(k):\n",
        "        for p in clusters[i]:\n",
        "            wss += get_dist(p, centroids[i]) ** 2\n",
        "\n",
        "    return wss\n",
        "\n",
        "# --- 1. PREPARASI DATA UNTUK SCALING ---\n",
        "\n",
        "# Transpose data: mengubah list of rows menjadi list of columns (fitur)\n",
        "# Dibutuhkan untuk menghitung mean dan std_dev per fitur\n",
        "transposed_features = transpose_data(clustering_features)\n",
        "scaled_features = []\n",
        "means = []\n",
        "stds = []\n",
        "\n",
        "# --- 2. PERHITUNGAN MANUAL MEAN DAN STD DEV ---\n",
        "for col_index in range(len(transposed_features)):\n",
        "    col_data = transposed_features[col_index]\n",
        "\n",
        "    # Hitung Statistik Manual\n",
        "    mean = calculate_mean(col_data)\n",
        "    std = calculate_std_dev(col_data, mean)\n",
        "\n",
        "    means.append(mean)\n",
        "    stds.append(std)\n",
        "\n",
        "print(f\"Mean Manual (Log Distance, Log Speed, Avg HR): {means}\")\n",
        "print(f\"Std Dev Manual (Log Distance, Log Speed, Avg HR): {stds}\")\n",
        "\n",
        "\n",
        "# --- 3. PENERAPAN MANUAL STANDARDISASI (Z = (X - Mu) / Sigma) ---\n",
        "for i in range(len(clustering_features)): # Loop melalui setiap pengguna\n",
        "    scaled_row = []\n",
        "\n",
        "    for j in range(len(clustering_features[i])): # Loop melalui setiap fitur (3 fitur)\n",
        "        val = clustering_features[i][j]\n",
        "        mean = means[j]\n",
        "        std = stds[j]\n",
        "\n",
        "        # Terapkan Z-Score secara manually\n",
        "        if std != 0:\n",
        "            scaled_val = (val - mean) / std\n",
        "        else:\n",
        "            # Jika std dev = 0 (fitur konstan), nilai Z-Score adalah 0\n",
        "            scaled_val = 0\n",
        "\n",
        "        scaled_row.append(scaled_val)\n",
        "\n",
        "    scaled_features.append(scaled_row)\n",
        "\n",
        "print(\"\\nPART 3 SELESAI. Data telah berhasil di Standardisasi (Scaled) dan siap untuk K-Means.\")"
      ],
      "metadata": {
        "id": "_fM0wkJHdULe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77023654-b3f9-425b-ea2b-d72341c0c402"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Manual (Log Distance, Log Speed, Avg HR): [14.0290378448561, 7.365519730191664, 1265.9262970798534]\n",
            "Std Dev Manual (Log Distance, Log Speed, Avg HR): [1.339166853168847, 0.33647599920429117, 174.29644293394162]\n",
            "\n",
            "PART 3 SELESAI. Data telah berhasil di Standardisasi (Scaled) dan siap untuk K-Means.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ELBOW METHOD**"
      ],
      "metadata": {
        "id": "d2-msKNJz4bU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sambungan dari PART 3 (menggunakan scaled_features dan helper functions)\n",
        "\n",
        "# K Optimal\n",
        "K_OPTIMAL = 3\n",
        "max_k = 8\n",
        "k_range = range(1, max_k + 1)\n",
        "wcss_list = [] # Re-initialize for safety if cell is run partially\n",
        "wcss_history_k3 = [] # Akan diisi dengan riwayat WCSS untuk Loss Curve\n",
        "\n",
        "# --- 1. METODE ELBOW (WCSS vs. K) ---\n",
        "\n",
        "print(\"Memulai Perhitungan Manual Elbow Method (WCSS)...\")\n",
        "# Loop untuk menghitung WCSS untuk setiap K\n",
        "for k in k_range:\n",
        "    wss = calculate_wss(scaled_features, k)\n",
        "    wcss_list.append(wss)\n",
        "    print(f\"K={k}: WCSS={wss:.2f}\")\n",
        "\n",
        "# Visualisasi Elbow Method\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(k_range, wcss_list, marker='o', linestyle='--')\n",
        "plt.title('Metode Elbow Manual (WCSS vs. K)', fontsize=14)\n",
        "plt.xlabel('Jumlah Klaster (K)')\n",
        "plt.ylabel('WCSS (Within-Cluster Sum of Squares)')\n",
        "plt.xticks(k_range)\n",
        "plt.grid(True)\n",
        "plt.savefig('elbow_method_manual.png')\n",
        "plt.close()\n",
        "\n",
        "\n",
        "# --- 2. LOSS CURVE (WCSS vs. ITERASI) ---\n",
        "\n",
        "# Jalankan K-Means final untuk K=3 dan ambil WCSS History\n",
        "print(f\"\\nMenghitung Loss Curve (WCSS vs. Iterasi) untuk K={K_OPTIMAL}...\")\n",
        "\n",
        "# Run manual_kmeans (now modified to return WSS history)\n",
        "# indices_k3 and centroids_k3 are not directly used in this cell but can be for debugging/further steps\n",
        "indices_k3, centroids_k3, wcss_history_k3 = manual_kmeans(scaled_features, K_OPTIMAL)\n",
        "\n",
        "# Visualisasi Loss Curve (WCSS vs. Iterasi)\n",
        "plt.figure(figsize=(8, 6))\n",
        "# Rentang X: 1 hingga jumlah iterasi yang terjadi\n",
        "plt.plot(range(1, len(wcss_history_k3) + 1), wcss_history_k3, marker='o', color='purple')\n",
        "plt.title(f'Loss Curve (WCSS vs. Iterasi) untuk K={K_OPTIMAL}', fontsize=14)\n",
        "plt.xlabel('Iterasi')\n",
        "plt.ylabel('WCSS (Menurun Menuju Konvergensi)')\n",
        "plt.grid(True)\n",
        "plt.savefig('convergence_loss_curve.png')\n",
        "plt.close()\n",
        "\n",
        "print(f\"\\nPART 4 SELESAI. K Optimal ditetapkan = {K_OPTIMAL}.\")\n",
        "print(\"1. Plot Elbow Method telah disimpan sebagai 'elbow_method_manual.png'.\")\n",
        "print(\"2. Plot Loss Curve (Konvergensi) telah disimpan sebagai 'convergence_loss_curve.png'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1yb94aCz32s",
        "outputId": "876a6d43-1cb4-4a51-d8d4-e74431fd3e61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memulai Perhitungan Manual Elbow Method (WCSS)...\n",
            "K=1: WCSS=717.00\n",
            "K=2: WCSS=445.72\n",
            "K=3: WCSS=331.35\n",
            "K=4: WCSS=280.89\n",
            "K=5: WCSS=245.62\n",
            "K=6: WCSS=227.86\n",
            "K=7: WCSS=211.24\n",
            "K=8: WCSS=197.45\n",
            "\n",
            "Menghitung Loss Curve (WCSS vs. Iterasi) untuk K=3...\n",
            "\n",
            "--- Iterasi 1/20 ---\n",
            "Cluster 0: Centroid = (0.2693, 0.9119, 1.3601), Ukuran = 62 pengguna\n",
            "Cluster 1: Centroid = (0.1903, -0.4891, -0.9083), Ukuran = 92 pengguna\n",
            "Cluster 2: Centroid = (-0.3977, -0.1342, -0.0089), Ukuran = 86 pengguna\n",
            "\n",
            "--- Iterasi 2/20 ---\n",
            "Cluster 0: Centroid = (0.4627, 0.9142, 1.1587), Ukuran = 75 pengguna\n",
            "Cluster 1: Centroid = (0.2206, -0.4993, -0.8985), Ukuran = 90 pengguna\n",
            "Cluster 2: Centroid = (-0.7274, -0.3150, -0.0805), Ukuran = 75 pengguna\n",
            "\n",
            "--- Iterasi 3/20 ---\n",
            "Cluster 0: Centroid = (0.5025, 0.8766, 1.0341), Ukuran = 83 pengguna\n",
            "Cluster 1: Centroid = (0.2734, -0.4046, -0.8030), Ukuran = 96 pengguna\n",
            "Cluster 2: Centroid = (-1.1140, -0.5560, -0.1433), Ukuran = 61 pengguna\n",
            "\n",
            "--- Iterasi 4/20 ---\n",
            "Cluster 0: Centroid = (0.5147, 0.8437, 1.0095), Ukuran = 85 pengguna\n",
            "Cluster 1: Centroid = (0.2688, -0.3487, -0.6985), Ukuran = 106 pengguna\n",
            "Cluster 2: Centroid = (-1.4744, -0.7093, -0.2401), Ukuran = 49 pengguna\n",
            "\n",
            "--- Iterasi 5/20 ---\n",
            "Cluster 0: Centroid = (0.4870, 0.8304, 1.0169), Ukuran = 86 pengguna\n",
            "Cluster 1: Centroid = (0.2623, -0.3327, -0.6593), Ukuran = 110 pengguna\n",
            "Cluster 2: Centroid = (-1.6077, -0.7913, -0.3395), Ukuran = 44 pengguna\n",
            "\n",
            "--- Iterasi 6/20 ---\n",
            "Cluster 0: Centroid = (0.4732, 0.8305, 1.0189), Ukuran = 86 pengguna\n",
            "Cluster 1: Centroid = (0.2518, -0.3333, -0.6378), Ukuran = 113 pengguna\n",
            "Cluster 2: Centroid = (-1.6866, -0.8236, -0.3794), Ukuran = 41 pengguna\n",
            "\n",
            "--- Iterasi 7/20 ---\n",
            "Cluster 0: Centroid = (0.4376, 0.8425, 1.0404), Ukuran = 86 pengguna\n",
            "Cluster 1: Centroid = (0.2406, -0.3399, -0.6184), Ukuran = 116 pengguna\n",
            "Cluster 2: Centroid = (-1.7248, -0.8690, -0.4669), Ukuran = 38 pengguna\n",
            "\n",
            "--- Iterasi 8/20 ---\n",
            "Cluster 0: Centroid = (0.4244, 0.8420, 1.0569), Ukuran = 86 pengguna\n",
            "Cluster 1: Centroid = (0.2332, -0.3350, -0.6103), Ukuran = 117 pengguna\n",
            "Cluster 2: Centroid = (-1.7239, -0.8978, -0.5270), Ukuran = 37 pengguna\n",
            "\n",
            "--- Iterasi 9/20 ---\n",
            "Cluster 0: Centroid = (0.4244, 0.8420, 1.0569), Ukuran = 86 pengguna\n",
            "Cluster 1: Centroid = (0.2332, -0.3350, -0.6103), Ukuran = 117 pengguna\n",
            "Cluster 2: Centroid = (-1.7239, -0.8978, -0.5270), Ukuran = 37 pengguna\n",
            "\n",
            "Algoritma Konvergen, menghentikan iterasi lebih awal.\n",
            "\n",
            "PART 4 SELESAI. K Optimal ditetapkan = 3.\n",
            "1. Plot Elbow Method telah disimpan sebagai 'elbow_method_manual.png'.\n",
            "2. Plot Loss Curve (Konvergensi) telah disimpan sebagai 'convergence_loss_curve.png'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 4: Execution & File Generation"
      ],
      "metadata": {
        "id": "8tDyxIVAdWFa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sambungan dari PART 4 (menggunakan scaled_features, original_features, badges, dan helper functions)\n",
        "\n",
        "from mpl_toolkits.mplot3d import Axes3D # Untuk plot 3D\n",
        "\n",
        "# K Optimal telah ditetapkan berdasarkan Elbow Method di Part 4\n",
        "K_OPTIMAL = 3\n",
        "\n",
        "# --- A. FINAL K-MEANS RUN (Mendapatkan Label Klaster) ---\n",
        "print(f\"Menjalankan K-Means final dengan K={K_OPTIMAL}...\")\n",
        "\n",
        "# Jalankan K-Means final untuk mendapatkan labels\n",
        "# manual_kmeans returns: cluster_indices_per_group, final_centroids, wss_history\n",
        "cluster_indices_per_group, final_centroids, _ = manual_kmeans(scaled_features, K_OPTIMAL)\n",
        "\n",
        "# Reconstruct final_labels from cluster_indices_per_group\n",
        "final_labels = [0] * len(scaled_features)\n",
        "for cluster_id, indices_in_cluster in enumerate(cluster_indices_per_group):\n",
        "    for original_idx in indices_in_cluster:\n",
        "        final_labels[original_idx] = cluster_id\n",
        "\n",
        "\n",
        "# --- B. PROFILING CLUSTER (Manual Group By and Mean) ---\n",
        "\n",
        "cluster_profiles = {}\n",
        "for i in range(K_OPTIMAL):\n",
        "    cluster_profiles[i] = {'Total_Distance': [], 'Avg_Speed': [], 'Avg_Heart_Rate': []}\n",
        "\n",
        "# 1. Mengelompokkan Fitur ASLI (non-scaled) berdasarkan Label Klaster\n",
        "for i in range(len(filtered_badges)): # Menggunakan filtered_badges yang sesuai\n",
        "    idx = final_labels[i]\n",
        "    data = original_features[i]\n",
        "\n",
        "    cluster_profiles[idx]['Total_Distance'].append(data['Total_Distance'])\n",
        "    cluster_profiles[idx]['Avg_Speed'].append(data['Avg_Speed'])\n",
        "    cluster_profiles[idx]['Avg_Heart_Rate'].append(data['Avg_Heart_Rate'])\n",
        "\n",
        "# 2. Menghitung Mean (Rata-rata) per Klaster untuk Profiling\n",
        "profile_summary = []\n",
        "for idx, profile in cluster_profiles.items():\n",
        "    mean_dist = calculate_mean(profile['Total_Distance'])\n",
        "    profile_summary.append({\n",
        "        'Cluster_Index': idx,\n",
        "        'Mean_Total_Distance': mean_dist,\n",
        "        'Mean_Avg_Speed': calculate_mean(profile['Avg_Speed']),\n",
        "        'Mean_Avg_Heart_Rate': calculate_mean(profile['Avg_Heart_Rate']),\n",
        "        'Count': len(profile['Total_Distance'])\n",
        "    })\n",
        "\n",
        "# 3. Menentukan Nama Klaster (Sortir berdasarkan Mean Total Distance)\n",
        "profile_summary.sort(key=lambda x: x['Mean_Total_Distance'])\n",
        "\n",
        "cluster_name_map = {}\n",
        "cluster_name_map[profile_summary[0]['Cluster_Index']] = \"1-Bronze (Basic)\" # Terendah\n",
        "cluster_name_map[profile_summary[1]['Cluster_Index']] = \"2-Silver (Standard)\" # Sedang\n",
        "cluster_name_map[profile_summary[2]['Cluster_Index']] = \"3-Gold (Premium)\" # Tertinggi\n",
        "\n",
        "print(\"\\nProfil Klaster (Rata-rata Fitur Asli):\")\n",
        "for summary in profile_summary:\n",
        "    name = cluster_name_map[summary['Cluster_Index']]\n",
        "    print(f\"- {name}: Jarak={summary['Mean_Total_Distance']:.0f}m, Speed={summary['Mean_Avg_Speed']:.2f} km/h, HR={summary['Mean_Avg_Heart_Rate']:.0f} bpm (N={summary['Count']})\")\n",
        "\n",
        "\n",
        "# --- C. SCATTER PLOT HASIL CLUSTERING ---\n",
        "\n",
        "# Map warna untuk visualisasi\n",
        "color_map = {\"1-Bronze (Basic)\": 'blue', \"2-Silver (Standard)\": 'green', \"3-Gold (Premium)\": 'red'}\n",
        "\n",
        "# Persiapan data untuk plotting\n",
        "x_3d = [p[0] for p in scaled_features] # Log Distance\n",
        "y_3d = [p[1] for p in scaled_features] # Log Speed\n",
        "z_3d = [p[2] for p in scaled_features] # Avg Heart Rate\n",
        "c_3d = [color_map[cluster_name_map[label]] for label in final_labels]\n",
        "\n",
        "# 1. Scatter Plot 3D (Menggunakan ketiga fitur)\n",
        "fig = plt.figure(figsize=(10, 8))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "# Scatter data points\n",
        "ax.scatter(x_3d, y_3d, z_3d, c=c_3d, marker='o', alpha=0.7)\n",
        "\n",
        "# Scatter centroids\n",
        "centroid_x = [c[0] for c in final_centroids]\n",
        "centroid_y = [c[1] for c in final_centroids]\n",
        "centroid_z = [c[2] for c in final_centroids]\n",
        "ax.scatter(centroid_x, centroid_y, centroid_z, marker='X', s=300, c='black')\n",
        "\n",
        "ax.set_title('Hasil Clustering K-Means (3D Plot)', fontsize=14)\n",
        "ax.set_xlabel('Log Distance (Scaled)')\n",
        "ax.set_ylabel('Log Speed (Scaled)')\n",
        "ax.set_zlabel('Avg Heart Rate (Scaled)')\n",
        "plt.tight_layout()\n",
        "plt.savefig('scatter_plot_3d.png')\n",
        "plt.close()\n",
        "print(\"\\n3D Scatter Plot telah disimpan sebagai 'scatter_plot_3d.png'\")\n",
        "\n",
        "\n",
        "# 2. Scatter Plot 2D (Untuk representasi yang lebih sederhana)\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.scatter(x_3d, y_3d, c=c_3d, alpha=0.7)\n",
        "\n",
        "# Tambahkan label centroid (hanya 2 dimensi pertama)\n",
        "centroid_colors = [color_map[cluster_name_map[i]] for i in cluster_name_map]\n",
        "plt.scatter(centroid_x, centroid_y, marker='X', s=200, c='black', edgecolors=centroid_colors, linewidths=2)\n",
        "\n",
        "plt.title('Hasil Clustering K-Means (Log Distance vs. Log Speed)', fontsize=14)\n",
        "plt.xlabel('Log Distance (Standardized)')\n",
        "plt.ylabel('Log Speed (Standardized)')\n",
        "plt.grid(True)\n",
        "plt.savefig('scatter_plot_2d.png')\n",
        "plt.close()\n",
        "print(\"2D Scatter Plot telah disimpan sebagai 'scatter_plot_2d.png'\")\n",
        "\n",
        "\n",
        "# --- D. EXPORT FINAL RESULT (Manual CSV Writing) ---\n",
        "\n",
        "csv_filename = \"segmentasi_pengguna_manual_final.csv\"\n",
        "header_row = [\"Badge_ID\", \"Total_Distance_Meters\", \"Avg_Speed_Kmh\", \"Avg_Heart_Rate_Bpm\", \"Cluster_Name\"]\n",
        "\n",
        "final_output_report = []\n",
        "for i in range(len(filtered_badges)): # Menggunakan filtered_badges\n",
        "    # Mengambil data asli dari filtered list\n",
        "    data = original_features[i]\n",
        "    # Mengambil nama klaster\n",
        "    name = cluster_name_map[final_labels[i]]\n",
        "\n",
        "    final_output_report.append([\n",
        "        filtered_badges[i], # Menggunakan filtered_badges\n",
        "        data['Total_Distance'],\n",
        "        data['Avg_Speed'],\n",
        "        data['Avg_Heart_Rate'],\n",
        "        name\n",
        "    ])\n",
        "\n",
        "\n",
        "with open(csv_filename, 'w', newline='') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow(header_row)\n",
        "    writer.writerows(final_output_report)\n",
        "\n",
        "print(f\"\\nPART 5 SELESAI. Hasil segmentasi akhir telah diexport ke: {csv_filename}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhkTFdEEdXfc",
        "outputId": "fd7a41e9-03c9-4636-be4d-6f2b53d89216"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Menjalankan K-Means final dengan K=3...\n",
            "\n",
            "--- Iterasi 1/20 ---\n",
            "Cluster 0: Centroid = (0.2693, 0.9119, 1.3601), Ukuran = 62 pengguna\n",
            "Cluster 1: Centroid = (0.1903, -0.4891, -0.9083), Ukuran = 92 pengguna\n",
            "Cluster 2: Centroid = (-0.3977, -0.1342, -0.0089), Ukuran = 86 pengguna\n",
            "\n",
            "--- Iterasi 2/20 ---\n",
            "Cluster 0: Centroid = (0.4627, 0.9142, 1.1587), Ukuran = 75 pengguna\n",
            "Cluster 1: Centroid = (0.2206, -0.4993, -0.8985), Ukuran = 90 pengguna\n",
            "Cluster 2: Centroid = (-0.7274, -0.3150, -0.0805), Ukuran = 75 pengguna\n",
            "\n",
            "--- Iterasi 3/20 ---\n",
            "Cluster 0: Centroid = (0.5025, 0.8766, 1.0341), Ukuran = 83 pengguna\n",
            "Cluster 1: Centroid = (0.2734, -0.4046, -0.8030), Ukuran = 96 pengguna\n",
            "Cluster 2: Centroid = (-1.1140, -0.5560, -0.1433), Ukuran = 61 pengguna\n",
            "\n",
            "--- Iterasi 4/20 ---\n",
            "Cluster 0: Centroid = (0.5147, 0.8437, 1.0095), Ukuran = 85 pengguna\n",
            "Cluster 1: Centroid = (0.2688, -0.3487, -0.6985), Ukuran = 106 pengguna\n",
            "Cluster 2: Centroid = (-1.4744, -0.7093, -0.2401), Ukuran = 49 pengguna\n",
            "\n",
            "--- Iterasi 5/20 ---\n",
            "Cluster 0: Centroid = (0.4870, 0.8304, 1.0169), Ukuran = 86 pengguna\n",
            "Cluster 1: Centroid = (0.2623, -0.3327, -0.6593), Ukuran = 110 pengguna\n",
            "Cluster 2: Centroid = (-1.6077, -0.7913, -0.3395), Ukuran = 44 pengguna\n",
            "\n",
            "--- Iterasi 6/20 ---\n",
            "Cluster 0: Centroid = (0.4732, 0.8305, 1.0189), Ukuran = 86 pengguna\n",
            "Cluster 1: Centroid = (0.2518, -0.3333, -0.6378), Ukuran = 113 pengguna\n",
            "Cluster 2: Centroid = (-1.6866, -0.8236, -0.3794), Ukuran = 41 pengguna\n",
            "\n",
            "--- Iterasi 7/20 ---\n",
            "Cluster 0: Centroid = (0.4376, 0.8425, 1.0404), Ukuran = 86 pengguna\n",
            "Cluster 1: Centroid = (0.2406, -0.3399, -0.6184), Ukuran = 116 pengguna\n",
            "Cluster 2: Centroid = (-1.7248, -0.8690, -0.4669), Ukuran = 38 pengguna\n",
            "\n",
            "--- Iterasi 8/20 ---\n",
            "Cluster 0: Centroid = (0.4244, 0.8420, 1.0569), Ukuran = 86 pengguna\n",
            "Cluster 1: Centroid = (0.2332, -0.3350, -0.6103), Ukuran = 117 pengguna\n",
            "Cluster 2: Centroid = (-1.7239, -0.8978, -0.5270), Ukuran = 37 pengguna\n",
            "\n",
            "--- Iterasi 9/20 ---\n",
            "Cluster 0: Centroid = (0.4244, 0.8420, 1.0569), Ukuran = 86 pengguna\n",
            "Cluster 1: Centroid = (0.2332, -0.3350, -0.6103), Ukuran = 117 pengguna\n",
            "Cluster 2: Centroid = (-1.7239, -0.8978, -0.5270), Ukuran = 37 pengguna\n",
            "\n",
            "Algoritma Konvergen, menghentikan iterasi lebih awal.\n",
            "\n",
            "Profil Klaster (Rata-rata Fitur Asli):\n",
            "- 1-Bronze (Basic): Jarak=183090m, Speed=1248.62 km/h, HR=1174 bpm (N=37)\n",
            "- 2-Silver (Standard): Jarak=1991622m, Speed=1432.85 km/h, HR=1160 bpm (N=117)\n",
            "- 3-Gold (Premium): Jarak=3508626m, Speed=2158.92 km/h, HR=1450 bpm (N=86)\n",
            "\n",
            "3D Scatter Plot telah disimpan sebagai 'scatter_plot_3d.png'\n",
            "2D Scatter Plot telah disimpan sebagai 'scatter_plot_2d.png'\n",
            "\n",
            "PART 5 SELESAI. Hasil segmentasi akhir telah diexport ke: segmentasi_pengguna_manual_final.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "# Data ini harusnya dihasilkan di PART 5\n",
        "\n",
        "# Asumsi data profil final yang sudah diurutkan (sesuai Mean Distance):\n",
        "# 1-Bronze (Terendah) = 37 pengguna\n",
        "# 2-Silver (Sedang)   = 117 pengguna\n",
        "# 3-Gold (Tertinggi)  = 86 pengguna\n",
        "\n",
        "# Catatan: Jumlah pengguna disesuaikan dengan output iterasi terakhir Anda\n",
        "cluster_sizes_raw = [37, 117, 86]\n",
        "# Diurutkan berdasarkan jumlah distance (terendah ke tertinggi)\n",
        "cluster_names = [\"1-Bronze (Basic)\", \"2-Silver (Standard)\", \"3-Gold (Premium)\"]\n",
        "cluster_colors = ['#8B4513', '#C0C0C0', '#FFD700'] # Warna Coklat/Perunggu, Perak, Emas\n",
        "\n",
        "total_users_final = sum(cluster_sizes_raw)\n",
        "percentages = [(size / total_users_final) * 100 for size in cluster_sizes_raw]\n",
        "\n",
        "plt.figure(figsize=(9, 6))\n",
        "bars = plt.bar(cluster_names, cluster_sizes_raw, color=cluster_colors, width=0.7)\n",
        "\n",
        "# Menambahkan label nilai absolut dan persentase di atas setiap bar\n",
        "for bar, size, percentage in zip(bars, cluster_sizes_raw, percentages):\n",
        "    yval = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, yval + 5, f'{size}\\n({percentage:.1f}%)',\n",
        "             ha='center', va='bottom', fontsize=10)\n",
        "\n",
        "plt.title(f'Distribusi Jumlah Pengguna di Klaster (Total N={total_users_final})', fontsize=14)\n",
        "plt.ylabel('Jumlah Pengguna', fontsize=12)\n",
        "plt.xlabel('Nama Klaster', fontsize=12)\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
        "plt.tight_layout()\n",
        "plt.savefig('cluster_size_distribution.png')\n",
        "plt.close()\n",
        "\n",
        "print(\"Bar Chart distribusi ukuran klaster telah disimpan sebagai 'cluster_size_distribution.png'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ifhhrdkMVwv",
        "outputId": "8fabfdef-76dd-4faa-f006-518463b74455"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bar Chart distribusi ukuran klaster telah disimpan sebagai 'cluster_size_distribution.png'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "# --- 1. LOAD DAN AGGREGASI DATA AWAL (658 PENGGUNA) ---\n",
        "file_name = 'data-1-Daily-Activity.csv'\n",
        "users_agg_raw = {}\n",
        "\n",
        "# (Memuat dan membersihkan data harian, sama seperti Part 1)\n",
        "with open(file_name, 'r') as f:\n",
        "    reader = csv.reader(f)\n",
        "    next(reader)\n",
        "\n",
        "    for row in reader:\n",
        "        try:\n",
        "            badge = row[10]\n",
        "            d = float(row[0]) if row[0] else 0\n",
        "            mt = float(row[1]) if row[1] else 0\n",
        "            asp = float(row[6]) if row[6] else 0\n",
        "            hr = float(row[8]) if row[8] else 0\n",
        "\n",
        "            # Filter 'd==0 and mt==0' masih diterapkan di level record\n",
        "            if d == 0 and mt == 0: continue\n",
        "\n",
        "            if badge not in users_agg_raw:\n",
        "                users_agg_raw[badge] = {'d': [], 'asp': [], 'hr': []}\n",
        "\n",
        "            users_agg_raw[badge]['d'].append(d)\n",
        "            users_agg_raw[badge]['asp'].append(asp)\n",
        "            users_agg_raw[badge]['hr'].append(hr)\n",
        "        except ValueError:\n",
        "            continue\n",
        "\n",
        "# Aggregasi data per pengguna\n",
        "initial_aggregated_data = []\n",
        "for b, v in users_agg_raw.items():\n",
        "    freq = len(v['d'])\n",
        "    if freq == 0: continue\n",
        "\n",
        "    initial_aggregated_data.append({\n",
        "        'user_id': b,\n",
        "        'Total_Distance': sum(v['d']),\n",
        "        'Avg_Speed': sum(v['asp']) / freq,\n",
        "        'Avg_Heart_Rate': sum(v['hr']) / freq\n",
        "    })\n",
        "\n",
        "total_initial_users = len(initial_aggregated_data)\n",
        "\n",
        "# --- 2. PERHITUNGAN DATA BERSIH VS. DATA HILANG/NOL (LEVEL PENGGUNA) ---\n",
        "\n",
        "# Inisialisasi penghitung untuk pengguna dengan nilai Nol (0) di level aggregasi\n",
        "zero_users_count = {\n",
        "    'Total_Distance': 0,\n",
        "    'Avg_Speed': 0,\n",
        "    'Avg_Heart_Rate': 0,\n",
        "}\n",
        "\n",
        "# Lakukan perhitungan\n",
        "for data in initial_aggregated_data:\n",
        "    if data['Total_Distance'] == 0:\n",
        "        zero_users_count['Total_Distance'] += 1\n",
        "\n",
        "    if data['Avg_Speed'] == 0:\n",
        "        zero_users_count['Avg_Speed'] += 1\n",
        "\n",
        "    if data['Avg_Heart_Rate'] == 0:\n",
        "        zero_users_count['Avg_Heart_Rate'] += 1\n",
        "\n",
        "# Hitung pengguna dengan data bersih (nilai > 0)\n",
        "clean_users_count = {}\n",
        "for key in zero_users_count.keys():\n",
        "    clean_users_count[key] = total_initial_users - zero_users_count[key]\n",
        "\n",
        "\n",
        "# --- 3. VISUALISASI STACKED BAR CHART (DATA BERSIH VS. HILANG/NOL) ---\n",
        "\n",
        "categories = ['Total_Distance', 'Avg_Speed', 'Avg_Heart_Rate']\n",
        "clean_counts = [clean_users_count[cat] for cat in categories]\n",
        "zero_counts = [zero_users_count[cat] for cat in categories]\n",
        "\n",
        "# Warna: Hijau untuk Bersih, Oranye untuk Nol\n",
        "color_clean = '#4CAF50' # Hijau\n",
        "color_zero = '#FF9800'  # Oranye\n",
        "\n",
        "plt.figure(figsize=(12, 7))\n",
        "\n",
        "# Bar Bawah (Data Bersih)\n",
        "plt.bar(categories, clean_counts, color=color_clean, label='Pengguna Data Bersih (Nilai > 0)')\n",
        "\n",
        "# Bar Atas (Data Hilang/Nol)\n",
        "# Bar ini akan ditumpuk di atas clean_counts\n",
        "plt.bar(categories, zero_counts, bottom=clean_counts, color=color_zero, label='Pengguna Data Hilang/Nol (0)')\n",
        "\n",
        "# Menambahkan Label Total di puncak setiap bar (semuanya harus 658)\n",
        "for i, total in enumerate(clean_counts):\n",
        "    total_val = clean_counts[i] + zero_counts[i]\n",
        "    plt.text(i, total_val + 10, f'{total_val}', ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
        "\n",
        "    # Menambahkan Label Nilai Nol (Oranye)\n",
        "    if zero_counts[i] > 0:\n",
        "        # Posisikan label di tengah bagian oranye\n",
        "        plt.text(i, clean_counts[i] + (zero_counts[i]/2), f'{zero_counts[i]}', ha='center', va='center', color='white', fontsize=10)\n",
        "\n",
        "    # Menambahkan Label Nilai Bersih (Hijau)\n",
        "    if clean_counts[i] > 0 and zero_counts[i] < (total_val * 0.9):\n",
        "        # Posisikan label di tengah bagian hijau (jika bagian oranye tidak terlalu besar)\n",
        "        plt.text(i, clean_counts[i]/2, f'{clean_counts[i]}', ha='center', va='center', color='white', fontsize=10)\n",
        "\n",
        "\n",
        "plt.title(f'Kualitas Data Agregasi: Pengguna Bersih vs. Pengguna Nol (N={total_initial_users} Pengguna)', fontsize=16)\n",
        "plt.ylabel('Jumlah Pengguna', fontsize=12)\n",
        "plt.legend(loc='upper right')\n",
        "plt.xticks(rotation=15, ha='right')\n",
        "plt.ylim(0, total_initial_users + 50) # Memberi ruang untuk label total\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.savefig('kualitas_data_agregasi_stacked.png')\n",
        "plt.close()\n",
        "\n",
        "print(f\"Total Pengguna Awal: {total_initial_users}\")\n",
        "print(f\"Pengguna dengan Total_Distance = 0: {zero_users_count['Total_Distance']}\")\n",
        "print(f\"Pengguna dengan Avg_Speed = 0: {zero_users_count['Avg_Speed']}\")\n",
        "print(f\"Pengguna dengan Avg_Heart_Rate = 0: {zero_users_count['Avg_Heart_Rate']}\")\n",
        "print(\"Visualisasi Stacked Bar Chart telah disimpan sebagai 'kualitas_data_agregasi_stacked.png'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQs2tfABNGUJ",
        "outputId": "94e62547-eeb1-4b00-d391-4f19880592c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Pengguna Awal: 658\n",
            "Pengguna dengan Total_Distance = 0: 0\n",
            "Pengguna dengan Avg_Speed = 0: 0\n",
            "Pengguna dengan Avg_Heart_Rate = 0: 418\n",
            "Visualisasi Stacked Bar Chart telah disimpan sebagai 'kualitas_data_agregasi_stacked.png'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "file_name = 'data-1-Daily-Activity.csv'\n",
        "raw_distances = []\n",
        "user_activity_counts = {}\n",
        "\n",
        "# --- 1. PENGHITUNGAN MANUAL (LOAD RAW DATA & COUNT FREQUENCY) ---\n",
        "\n",
        "with open(file_name, 'r') as f:\n",
        "    reader = csv.reader(f)\n",
        "    next(reader) # Skip header\n",
        "\n",
        "    for row in reader:\n",
        "        try:\n",
        "            distance = float(row[0]) if row[0] else 0\n",
        "            badge = row[10]\n",
        "\n",
        "            # Kumpulkan jarak untuk Plot 1\n",
        "            if distance > 0:\n",
        "                raw_distances.append(distance)\n",
        "\n",
        "            # Hitung frekuensi per pengguna untuk Plot 2\n",
        "            if badge in user_activity_counts:\n",
        "                user_activity_counts[badge] += 1\n",
        "            else:\n",
        "                user_activity_counts[badge] = 1\n",
        "\n",
        "        except (ValueError, IndexError):\n",
        "            continue\n",
        "\n",
        "# Ekstrak Frekuensi untuk Plot 2\n",
        "frequencies = list(user_activity_counts.values())\n",
        "\n",
        "# --- 2. VISUALISASI DUA PLOT ---\n",
        "\n",
        "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 6))\n",
        "fig.suptitle('Analisis Distribusi Data Aktivitas', fontsize=16)\n",
        "\n",
        "# A. PLOT 1: DISTRIBUSI JARAK AKTIVITAS HARIAN (Raw Data)\n",
        "# Gunakan Log Transform pada sumbu X karena data jarak pasti skewed\n",
        "# Matplotlib dapat menghitung log scale di sumbu X.\n",
        "axes[0].hist(raw_distances, bins=50, color='#1f77b4', edgecolor='black', log=False)\n",
        "axes[0].set_title('Distribusi Jarak Harian (Raw Data)', fontsize=13)\n",
        "axes[0].set_xlabel('Jarak Aktivitas (meter)')\n",
        "axes[0].set_ylabel('Jumlah Aktivitas (Record)', fontsize=11)\n",
        "axes[0].ticklabel_format(style='plain', axis='y') # Cegah notasi ilmiah pada sumbu Y\n",
        "axes[0].grid(axis='y', linestyle='--', alpha=0.6)\n",
        "\n",
        "# B. PLOT 2: FREKUENSI AKTIVITAS PER PENGGUNA (Users Frequency)\n",
        "# Menunjukkan seberapa sering 658 pengguna mencatat data.\n",
        "axes[1].hist(frequencies, bins=max(frequencies) if max(frequencies) < 50 else 50, color='#ff7f0e', edgecolor='black')\n",
        "axes[1].set_title(f'Frekuensi Aktivitas per Pengguna (N={len(frequencies)} Pengguna)', fontsize=13)\n",
        "axes[1].set_xlabel('Jumlah Record Harian per Pengguna')\n",
        "axes[1].set_ylabel('Jumlah Pengguna', fontsize=11)\n",
        "axes[1].grid(axis='y', linestyle='--', alpha=0.6)\n",
        "axes[1].set_xlim(0, np.percentile(frequencies, 95)) # Batasi sumbu X agar plot tidak terlalu lebar karena ada outliers (super user)\n",
        "\n",
        "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "plt.savefig('eda_daily_frequency_distribution.png')\n",
        "plt.close()\n",
        "\n",
        "print(f\"Visualisasi Distribusi Data Harian dan Frekuensi Pengguna telah disimpan sebagai 'eda_daily_frequency_distribution.png'.\")"
      ],
      "metadata": {
        "id": "j4HVDdtsN-7Y",
        "outputId": "05aa3319-5ff0-48b1-d650-08a8106cdd96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Visualisasi Distribusi Data Harian dan Frekuensi Pengguna telah disimpan sebagai 'eda_daily_frequency_distribution.png'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "file_name = 'data-1-Daily-Activity.csv' # Nama file akan disesuaikan jika berbeda\n",
        "\n",
        "# --- 1. AGREGASI DATA PER PENGGUNA (Badge_ID) ---\n",
        "user_activity_data = {}\n",
        "\n",
        "with open(file_name, 'r') as f:\n",
        "    reader = csv.reader(f)\n",
        "    next(reader)\n",
        "\n",
        "    for row_idx, row in enumerate(reader):\n",
        "        try:\n",
        "            user_id = row[10] # Badge_ID\n",
        "\n",
        "            if user_id not in user_activity_data:\n",
        "                user_activity_data[user_id] = {\n",
        "                    'Total_Distance_sum': 0.0,\n",
        "                    'Moving_Time_sum': 0.0,\n",
        "                    'Avg_Speed_vals': [],\n",
        "                    'Avg_Heart_Rate_vals': [],\n",
        "                    'Avg_Cadence_vals': [],\n",
        "                    'Activity_Count': 0\n",
        "                }\n",
        "\n",
        "            dist = float(row[0]) if row[0] else 0.0\n",
        "            time = float(row[1]) if row[1] else 0.0\n",
        "            speed = float(row[6]) if row[6] else 0.0\n",
        "            hr = float(row[8]) if row[8] else 0.0\n",
        "            cadence = float(row[9]) if row[9] else 0.0\n",
        "\n",
        "            user_activity_data[user_id]['Total_Distance_sum'] += dist\n",
        "            user_activity_data[user_id]['Moving_Time_sum'] += time\n",
        "\n",
        "            if speed > 0.0: user_activity_data[user_id]['Avg_Speed_vals'].append(speed)\n",
        "            if hr > 0.0: user_activity_data[user_id]['Avg_Heart_Rate_vals'].append(hr)\n",
        "            if cadence > 0.0: user_activity_data[user_id]['Avg_Cadence_vals'].append(cadence)\n",
        "\n",
        "            user_activity_data[user_id]['Activity_Count'] += 1\n",
        "        except (ValueError, IndexError):\n",
        "            continue\n",
        "\n",
        "aggregated_data_dicts = []\n",
        "for user_id, data in user_activity_data.items():\n",
        "    avg_speed = np.mean(data['Avg_Speed_vals']) if data['Avg_Speed_vals'] else 0.0\n",
        "    avg_heart_rate = np.mean(data['Avg_Heart_Rate_vals']) if data['Avg_Heart_Rate_vals'] else 0.0\n",
        "    avg_cadence = np.mean(data['Avg_Cadence_vals']) if data['Avg_Cadence_vals'] else 0.0\n",
        "\n",
        "    aggregated_data_dicts.append({\n",
        "        'Total_Distance': data['Total_Distance_sum'],\n",
        "        'Moving_Time': data['Moving_Time_sum'],\n",
        "        'Avg_Speed': avg_speed,\n",
        "        'Avg_Heart_Rate': avg_heart_rate,\n",
        "        'Avg_Cadence': avg_cadence,\n",
        "        'Frequency': data['Activity_Count']\n",
        "    })\n",
        "\n",
        "# --- 2. STATISTIK DESKRIPTIF DENGAN PANDAS ---\n",
        "df_agg = pd.DataFrame(aggregated_data_dicts)\n",
        "descriptive_stats = df_agg.describe().T\n",
        "print(\"\\n--- STATISTIK DESKRIPTIF DATA TERAGREGASI ---\")\n",
        "print(descriptive_stats)\n",
        "descriptive_stats.to_csv('descriptive_stats_agg.csv')\n",
        "print(\"\\nStatistik deskriptif telah disimpan sebagai 'descriptive_stats_agg.csv'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAjqUg_f-qK3",
        "outputId": "34bfd811-b563-4086-a0f8-c5d21850f631"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- STATISTIK DESKRIPTIF DATA TERAGREGASI ---\n",
            "                count          mean           std      min            25%  \\\n",
            "Total_Distance  658.0  1.450069e+06  1.798777e+06  25100.0  220728.250000   \n",
            "Moving_Time     658.0  8.187792e+04  7.934625e+04    840.0   14995.000000   \n",
            "Avg_Speed       658.0  1.480819e+03  5.096931e+02     10.0    1184.475000   \n",
            "Avg_Heart_Rate  658.0  4.617360e+02  6.188215e+02      0.0       0.000000   \n",
            "Avg_Cadence     658.0  9.702703e+02  5.343824e+02      0.0    1002.426573   \n",
            "Frequency       658.0  3.367629e+01  3.067049e+01      1.0       6.000000   \n",
            "\n",
            "                         50%           75%           max  \n",
            "Total_Distance  938841.50000  1.929158e+06  1.808272e+07  \n",
            "Moving_Time      61111.50000  1.258072e+05  4.652980e+05  \n",
            "Avg_Speed         1357.77027  1.673210e+03  5.083855e+03  \n",
            "Avg_Heart_Rate       0.00000  1.158833e+03  1.767000e+03  \n",
            "Avg_Cadence       1123.37500  1.278326e+03  2.066523e+03  \n",
            "Frequency           26.50000  5.300000e+01  1.810000e+02  \n",
            "\n",
            "Statistik deskriptif telah disimpan sebagai 'descriptive_stats_agg.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "\n",
        "file_name = 'data-1-Daily-Activity.csv' # Pastikan nama file ini sudah diunggah ke Colab\n",
        "\n",
        "# --- HELPER FUNCTIONS (Diambil dari Part 3 Asli) ---\n",
        "def calculate_mean(data_list):\n",
        "    if not data_list: return 0.0\n",
        "    return sum(data_list) / len(data_list)\n",
        "\n",
        "def calculate_std_dev(data_list, mean):\n",
        "    # Menggunakan (N-1) untuk Standard Deviation Sampel (sesuai NumPy/Pandas)\n",
        "    if not data_list or len(data_list) < 2: return 0.0\n",
        "    variance = sum([(x - mean) ** 2 for x in data_list]) / (len(data_list) - 1)\n",
        "    return math.sqrt(variance)\n",
        "\n",
        "# --- 1. DATA AGGREGATION & INITIAL DATA QUALITY CHECK (Per Baris Harian) ---\n",
        "\n",
        "user_activity_data = {}\n",
        "total_records = 0\n",
        "relevant_cols_index = {\n",
        "    0: 'distance_meters', 1: 'moving_time_seconds',\n",
        "    6: 'average_speed_kmh', 8: 'average_heartrate_bpm', 9: 'average_cadence_spm'\n",
        "}\n",
        "invalid_counts = {k: 0 for k in relevant_cols_index.keys()}\n",
        "\n",
        "with open(file_name, 'r') as f:\n",
        "    reader = csv.reader(f)\n",
        "    next(reader)\n",
        "\n",
        "    for row_idx, row in enumerate(reader):\n",
        "        total_records += 1\n",
        "\n",
        "        # A. Hitung Kualitas Data Harian (Nol/Kosong)\n",
        "        for index in relevant_cols_index.keys():\n",
        "            cell_value = row[index]\n",
        "            is_invalid = cell_value == '' or (cell_value and float(cell_value) == 0.0)\n",
        "            if is_invalid:\n",
        "                invalid_counts[index] += 1\n",
        "\n",
        "        # B. Agregasi Data Per Pengguna\n",
        "        try:\n",
        "            user_id = row[10] # Badge_ID\n",
        "            if user_id not in user_activity_data:\n",
        "                user_activity_data[user_id] = {\n",
        "                    'Total_Distance_sum': 0.0, 'Moving_Time_sum': 0.0,\n",
        "                    'Avg_Speed_vals': [], 'Avg_Heart_Rate_vals': [], 'Avg_Cadence_vals': [],\n",
        "                    'Activity_Count': 0\n",
        "                }\n",
        "\n",
        "            # Parsing data, menggunakan 0.0 jika kosong\n",
        "            dist = float(row[0]) if row[0] else 0.0\n",
        "            time = float(row[1]) if row[1] else 0.0\n",
        "            speed = float(row[6]) if row[6] else 0.0\n",
        "            hr = float(row[8]) if row[8] else 0.0\n",
        "            cadence = float(row[9]) if row[9] else 0.0\n",
        "\n",
        "            user_activity_data[user_id]['Total_Distance_sum'] += dist\n",
        "            user_activity_data[user_id]['Moving_Time_sum'] += time\n",
        "\n",
        "            # Kumpulkan nilai > 0 untuk penghitungan rata-rata yang benar\n",
        "            if speed > 0.0: user_activity_data[user_id]['Avg_Speed_vals'].append(speed)\n",
        "            if hr > 0.0: user_activity_data[user_id]['Avg_Heart_Rate_vals'].append(hr)\n",
        "            if cadence > 0.0: user_activity_data[user_id]['Avg_Cadence_vals'].append(cadence)\n",
        "\n",
        "            user_activity_data[user_id]['Activity_Count'] += 1\n",
        "        except (ValueError, IndexError):\n",
        "            continue\n",
        "\n",
        "# --- 2. FINAL AGGREGATION & DATA FILTERING (Menghasilkan 658 dan 240 pengguna) ---\n",
        "\n",
        "aggregated_data_dicts = []\n",
        "original_features = [] # 240 pengguna valid, nilai mentah\n",
        "clustering_features_log = [] # 240 pengguna valid, nilai Log(X+1)\n",
        "\n",
        "for data in user_activity_data.values():\n",
        "    avg_speed = np.mean(data['Avg_Speed_vals']) if data['Avg_Speed_vals'] else 0.0\n",
        "    avg_heart_rate = np.mean(data['Avg_Heart_Rate_vals']) if data['Avg_Heart_Rate_vals'] else 0.0\n",
        "    avg_cadence = np.mean(data['Avg_Cadence_vals']) if data['Avg_Cadence_vals'] else 0.0\n",
        "\n",
        "    agg_dict = {\n",
        "        'Total_Distance': data['Total_Distance_sum'], 'Moving_Time': data['Moving_Time_sum'],\n",
        "        'Avg_Speed': avg_speed, 'Avg_Heart_Rate': avg_heart_rate, 'Avg_Cadence': avg_cadence,\n",
        "        'Frequency': data['Activity_Count']\n",
        "    }\n",
        "    aggregated_data_dicts.append(agg_dict)\n",
        "\n",
        "    # Filtering untuk 3 Fitur Kunci (untuk K-Means)\n",
        "    features_to_select = ['Total_Distance', 'Avg_Speed', 'Avg_Heart_Rate']\n",
        "    is_valid_user = all(agg_dict[feature] != 0 for feature in features_to_select)\n",
        "\n",
        "    if is_valid_user:\n",
        "        # Data Asli (Raw) untuk 240 pengguna\n",
        "        original_features.append({\n",
        "            'Total_Distance': agg_dict['Total_Distance'], 'Avg_Speed': agg_dict['Avg_Speed'], 'Avg_Heart_Rate': agg_dict['Avg_Heart_Rate']\n",
        "        })\n",
        "\n",
        "        # Data Log Transformed (Log(X+1)) untuk 240 pengguna\n",
        "        log_dist = math.log(agg_dict['Total_Distance'] + 1)\n",
        "        log_speed = math.log(agg_dict['Avg_Speed'] + 1)\n",
        "        avg_hr = agg_dict['Avg_Heart_Rate']\n",
        "        clustering_features_log.append([log_dist, log_speed, avg_hr])\n",
        "\n",
        "# --- 3. STANDARD SCALING (MENGHASILKAN DATA FINAL UNTUK PLOT) ---\n",
        "\n",
        "# Transpose dan hitung statistik\n",
        "transposed_log_features = [[row[i] for row in clustering_features_log] for i in range(len(clustering_features_log[0]))]\n",
        "scaled_features = []\n",
        "means = [calculate_mean(col) for col in transposed_log_features]\n",
        "stds = [calculate_std_dev(col, means[i]) for i, col in enumerate(transposed_log_features)]\n",
        "\n",
        "# Terapkan Standardisasi Z-Score\n",
        "for row in clustering_features_log:\n",
        "    scaled_row = [(row[j] - means[j]) / stds[j] if stds[j] != 0 else 0 for j in range(len(row))]\n",
        "    scaled_features.append(scaled_row)\n",
        "\n",
        "# Konversi ke DataFrame untuk Plot Distribusi\n",
        "df_raw = pd.DataFrame(original_features)\n",
        "df_log = pd.DataFrame(clustering_features_log, columns=['Log_Distance', 'Log_Speed', 'Avg_Heart_Rate'])\n",
        "df_scaled = pd.DataFrame(scaled_features, columns=['Scaled_Log_Distance', 'Scaled_Log_Speed', 'Scaled_Avg_Heart_Rate'])\n",
        "\n",
        "# --- 4. VISUALISASI 1: KUALITAS DATA HARIAN (STACKED BAR CHART) ---\n",
        "column_names = list(relevant_cols_index.values())\n",
        "invalid_data = list(invalid_counts.values())\n",
        "clean_data = [total_records - invalid for invalid in invalid_data]\n",
        "\n",
        "plt.figure(figsize=(12, 7))\n",
        "x_pos = np.arange(len(column_names))\n",
        "bar_width = 0.8\n",
        "plt.bar(x_pos, clean_data, color='#4CAF50', edgecolor='white', width=bar_width, label='Data Bersih (Nilai > 0)')\n",
        "plt.bar(x_pos, invalid_data, color='#FF5722', edgecolor='white', width=bar_width, bottom=clean_data, label='Data Hilang/Nol (Invalid)')\n",
        "plt.title(\"Kualitas Data Mentah: Data Bersih vs. Data Hilang/Nol (0) (N=22159 Records)\", fontsize=14)\n",
        "plt.xticks(x_pos, column_names, rotation=25, ha='right')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig('eda_data_quality_daily_bar_chart.png')\n",
        "plt.close()\n",
        "print(f\"Total Baris Data Ditemukan: {total_records}\")\n",
        "print(\"Visualisasi Kualitas Data Harian telah disimpan sebagai 'eda_data_quality_daily_bar_chart.png'\")\n",
        "\n",
        "\n",
        "# --- 5. VISUALISASI 2: STATISTIK DESKRIPTIF (N=658) ---\n",
        "df_agg_all = pd.DataFrame(aggregated_data_dicts)\n",
        "descriptive_stats = df_agg_all.describe().T\n",
        "\n",
        "print(\"\\n--- STATISTIK DESKRIPTIF DATA TERAGREGASI (N=658 Pengguna) ---\")\n",
        "print(descriptive_stats)\n",
        "descriptive_stats.to_csv('descriptive_stats_agg.csv')\n",
        "print(\"Statistik deskriptif telah disimpan sebagai 'descriptive_stats_agg.csv'\")\n",
        "\n",
        "\n",
        "# --- 6. VISUALISASI 3: PERBANDINGAN DISTRIBUSI (3x3 HISTOGRAM) (N=240) ---\n",
        "feature_cols = ['Total_Distance', 'Avg_Speed', 'Avg_Heart_Rate']\n",
        "log_cols = ['Log_Distance', 'Log_Speed', 'Avg_Heart_Rate']\n",
        "scaled_cols = ['Scaled_Log_Distance', 'Scaled_Log_Speed', 'Scaled_Avg_Heart_Rate']\n",
        "\n",
        "fig, axes = plt.subplots(3, 3, figsize=(15, 15))\n",
        "fig.suptitle('Visualisasi Distribusi Fitur Sebelum dan Sesudah Transformasi (N=240 Pengguna)', fontsize=16, y=1.02)\n",
        "bins_count = 30\n",
        "\n",
        "dfs = [df_raw, df_log, df_scaled]\n",
        "titles = ['Data Agregasi Mentah', 'Setelah Log(X+1) Transform', 'Setelah Standard Scaling (Z-Score)']\n",
        "colors = ['#1f77b4', '#ff7f0e', '#2ca02c']\n",
        "col_map = [feature_cols, log_cols, scaled_cols]\n",
        "\n",
        "for i in range(3):\n",
        "    df = dfs[i]\n",
        "    current_cols = col_map[i]\n",
        "\n",
        "    for j in range(3):\n",
        "        ax = axes[i, j]\n",
        "        col = current_cols[j]\n",
        "\n",
        "        ax.hist(df[col], bins=bins_count, color=colors[i], edgecolor='black', alpha=0.7)\n",
        "\n",
        "        mean_val = df[col].mean()\n",
        "        ax.axvline(mean_val, color='r', linestyle='dashed', linewidth=2, label=f'Mean: {mean_val:.2f}')\n",
        "\n",
        "        if i == 0: ax.set_title(f'Distribusi {feature_cols[j]}', fontsize=12)\n",
        "        if j == 0: ax.set_ylabel(titles[i], fontsize=11, fontweight='bold')\n",
        "        if i == 2: ax.set_xlabel(col)\n",
        "\n",
        "        ax.legend(fontsize=8)\n",
        "        ax.grid(axis='y', linestyle='--', alpha=0.6)\n",
        "\n",
        "plt.tight_layout(rect=[0, 0.03, 1, 0.98])\n",
        "plt.savefig('eda_distribution_comparison_3x3.png')\n",
        "plt.close() # Aman menggunakan close() setelah savefig()\n",
        "print(\"Visualisasi perbandingan distribusi telah disimpan sebagai 'eda_distribution_comparison_3x3.png'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4u8WiQu_kkt",
        "outputId": "3adec8a6-ad60-4407-acc6-73b494979c41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Baris Data Ditemukan: 22159\n",
            "Visualisasi Kualitas Data Harian telah disimpan sebagai 'eda_data_quality_daily_bar_chart.png'\n",
            "\n",
            "--- STATISTIK DESKRIPTIF DATA TERAGREGASI (N=658 Pengguna) ---\n",
            "                count          mean           std      min            25%  \\\n",
            "Total_Distance  658.0  1.450069e+06  1.798777e+06  25100.0  220728.250000   \n",
            "Moving_Time     658.0  8.187792e+04  7.934625e+04    840.0   14995.000000   \n",
            "Avg_Speed       658.0  1.480819e+03  5.096931e+02     10.0    1184.475000   \n",
            "Avg_Heart_Rate  658.0  4.617360e+02  6.188215e+02      0.0       0.000000   \n",
            "Avg_Cadence     658.0  9.702703e+02  5.343824e+02      0.0    1002.426573   \n",
            "Frequency       658.0  3.367629e+01  3.067049e+01      1.0       6.000000   \n",
            "\n",
            "                         50%           75%           max  \n",
            "Total_Distance  938841.50000  1.929158e+06  1.808272e+07  \n",
            "Moving_Time      61111.50000  1.258072e+05  4.652980e+05  \n",
            "Avg_Speed         1357.77027  1.673210e+03  5.083855e+03  \n",
            "Avg_Heart_Rate       0.00000  1.158833e+03  1.767000e+03  \n",
            "Avg_Cadence       1123.37500  1.278326e+03  2.066523e+03  \n",
            "Frequency           26.50000  5.300000e+01  1.810000e+02  \n",
            "Statistik deskriptif telah disimpan sebagai 'descriptive_stats_agg.csv'\n",
            "Visualisasi perbandingan distribusi telah disimpan sebagai 'eda_distribution_comparison_3x3.png'\n"
          ]
        }
      ]
    }
  ]
}